{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d008c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import GaussianNoise, RandomFlip, RandomTranslation, RandomRotation, RandomZoom, RandomContrast\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a919a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoading():\n",
    "    def __init__(self, X_dir, Y_dir, hyper):\n",
    "        self.X_dirs = glob(os.path.join(X_dir, '*.png'))\n",
    "        self.X_dirs.sort()\n",
    "        self.Y_dirs = glob(os.path.join(Y_dir, '*.png'))\n",
    "        self.Y_dirs.sort()\n",
    "        self.w = hyper['Width']\n",
    "        self.h = hyper['Height']\n",
    "        self.X_imgs_temp = self.loadImgs(self.X_dirs)\n",
    "        self.X = self.inputAlign(self.X_imgs_temp)\n",
    "        del self.X_imgs_temp\n",
    "        self.Y = self.loadImgs(self.Y_dirs, norm=False, axis=0)\n",
    "  \n",
    "        #self.X_train, self.Y_train, self.X_valid, self.Y_valid = train_test_split(self.X_dirs, self.Y_dirs, test_size=0.2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def inputAlign(self, imgs):\n",
    "        \n",
    "        length = imgs.shape[-1]\n",
    "        \n",
    "        X = np.zeros((length, self.h, self.w, 4))\n",
    "        \n",
    "        for i in range(length):\n",
    "            seq = np.zeros((self.h, self.w, 4))\n",
    "\n",
    "            for j in range(seq.shape[-1]):\n",
    "                if i - j >= 0:\n",
    "                    seq[...,j] = imgs[..., i-j]\n",
    "            X[i,...] = seq\n",
    "            \n",
    "        return X\n",
    "        \n",
    "        \n",
    "    def loadImgs(self, img_dirs, w=256, h=256, norm=True, axis=-1):\n",
    "    \n",
    "        outputs = None\n",
    "\n",
    "        for path in img_dirs:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (h,w))\n",
    "            if norm:\n",
    "                img = img / 255.0\n",
    "\n",
    "            if outputs is None:\n",
    "                if axis == -1:\n",
    "                    outputs = img.reshape((h,w,1))\n",
    "                elif axis == 0:\n",
    "                    outputs = img.reshape((1,h,w,1))\n",
    "            else:\n",
    "                if axis == -1:\n",
    "                    outputs = np.concatenate((outputs, img.reshape(h,w,1)), axis=axis)\n",
    "                elif axis == 0:\n",
    "                    outputs = np.concatenate((outputs, img.reshape(1,h,w,1)), axis=axis)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395c9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoaderSingle(tf.data.Dataset):\n",
    "    def __new__(self, X_dir, Y_dir, hyper):\n",
    "        self.X_dirs = glob(os.path.join(X_dir, '*.png'))\n",
    "        self.X_dirs.sort()\n",
    "        self.Y_dirs = glob(os.path.join(Y_dir, '*.png'))\n",
    "        self.Y_dirs.sort()\n",
    "        self.w = hyper['Width']\n",
    "        self.h = hyper['Height']\n",
    "        self.X_imgs_temp = self.loadImgs(self, self.X_dirs)\n",
    "        self.X = self.inputAlign(self, self.X_imgs_temp)\n",
    "        del self.X_imgs_temp\n",
    "        self.Y = self.loadImgs(self, self.Y_dirs, norm=False, axis=0)\n",
    "        \n",
    "        return tf.data.Dataset.from_tensor_slices({'x': self.X, 'y': self.Y})\n",
    "        #self.X_train, self.Y_train, self.X_valid, self.Y_valid = train_test_split(self.X_dirs, self.Y_dirs, test_size=0.2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def inputAlign(self, imgs):\n",
    "        \n",
    "        length = imgs.shape[-1]\n",
    "        \n",
    "        X = np.zeros((length, self.h, self.w, 4))\n",
    "        \n",
    "        for i in range(length):\n",
    "            seq = np.zeros((self.h, self.w, 4))\n",
    "\n",
    "            for j in range(seq.shape[-1]):\n",
    "                if i - j >= 0:\n",
    "                    seq[...,j] = imgs[..., i-j]\n",
    "            X[i,...] = seq\n",
    "            \n",
    "        return X\n",
    "        \n",
    "        \n",
    "    def loadImgs(self, img_dirs, w=256, h=256, norm=True, axis=-1):\n",
    "    \n",
    "        outputs = None\n",
    "\n",
    "        for path in img_dirs:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (h,w))\n",
    "            if norm:\n",
    "                img = img / 255.0\n",
    "                \n",
    "            if outputs is None:\n",
    "                if axis == -1:\n",
    "                    outputs = img.reshape((h,w,1))\n",
    "                elif axis == 0:\n",
    "                    outputs = img.reshape((1,h,w,1))\n",
    "            else:\n",
    "                if axis == -1:\n",
    "                    outputs = np.concatenate((outputs, img.reshape(h,w,1)), axis=axis)\n",
    "                elif axis == 0:\n",
    "                    outputs = np.concatenate((outputs, img.reshape(1,h,w,1)), axis=axis)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473f0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 06:25:41.120479: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-07 06:25:41.477128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22135 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "x_dir = '/docker/i2i/EntireData/01/set01/fluoroReal'\n",
    "y_dir = '/docker/i2i/EntireData/01/set01/fluoroAll_DN'\n",
    "hyper = {'Width':256, 'Height':256}\n",
    "test = dataLoaderSingle(x_dir, y_dir, hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6160474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            time.sleep(0.02)\n",
    "    print(\"Execution time: \", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c59cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  5.586222911952063\n"
     ]
    }
   ],
   "source": [
    "benchmark(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e375e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  5.587293624994345\n"
     ]
    }
   ],
   "source": [
    "benchmark(test.prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9989ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 06:27:05.630900: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  10.993959047016688\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf.data.Dataset.range(2).interleave(lambda _: test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d215f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  10.982175072014797\n"
     ]
    }
   ],
   "source": [
    "benchmark(tf.data.Dataset.range(2).interleave(lambda _: test,\n",
    "                                              num_parallel_calls=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1cd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=9,\n",
    "                     width_shift_range=0.16,\n",
    "                     height_shift_range=0.16,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='constant',\n",
    "                     cval=0,\n",
    "                     zoom_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854a26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataLoading(x_dir, y_dir, hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd049640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 256, 256, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e95dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 256, 256, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d03890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "seed = 1\n",
    "image_datagen.fit(data.X, augment=True, seed=seed)\n",
    "mask_datagen.fit(data.Y, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b5af457",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = image_datagen.flow(data.X, seed=seed)\n",
    "mask_gen = mask_datagen.flow(data.Y, seed=seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
